# COMO: CrOss-Mamba Interaction and Offset-Guided Fusion for Multimodal Object Detection

## ğŸ“– Introduction
This repository contains the official implementation of **COMO**, a framework designed to improve multimodal object detection through **CrOss-Mamba interaction** and **Offset-guided fusion**.  
Our approach mitigates offset effects, reduces computational costs, and improves the accuracy of multimodal object detection in remote sensing scenarios.

<p align="center">
  <img src="docs/framework.png" alt="COMO Framework" width="80%">
</p>

---

## ğŸ›  Requirements

- **Python**: 3.11  
- **PyTorch**: 2.0.0
- **Numpy**: 1.23.5
- **CUDA**: 11.8~12.5

- Other requirements can be seen in requirement.txt   

Install dependencies step by step:

```bash
# 1. Install dependencies
pip install causal_conv1d-1.1.1+cu118torch2.0cxx11abiFALSE-cp311-cp311-linux_x86_64.whl
pip install mamba_ssm-1.2.0.post1+cu118torch2.0cxx11abiFALSE-cp311-cp311-linux_x86_64.whl
# mamba_ssm-1.2.0é“¾æ¥: https://pan.baidu.com/s/16X_vhdSkRB_9y6GKOgv4cw?pwd=1234 æå–ç : 1234

# 2. Replace mamba_simple.py & local_scan.py
# (copy modified ./ssm/mamba_simple.py and ./ssm/local_scan.py  into the installed mamba-ssm package folder as fig.1 )

# 3. Replace selective_scan_interface.py 
# (copy  modified ./ssm/selective_scan_interface.py into the correct path in mamba-ssm/ops)

mamba-ssm/
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ mamba_simple.py     â† Replace this file (Step 2)
â”‚   â””â”€â”€  local_scan.py       â† Replace this file (Step 2)
â”œâ”€â”€ ops/
â”‚   â””â”€â”€ selective_scan_interface.py â† Replace this file (Step 3)
````

---

## ğŸ“Š  dataset
The DroneVehicle dataset is available through Baidu Cloud:

ğŸ”— Download Link: [Baidu Cloud Drive](https://pan.baidu.com/s/1V4A8cqIOd2-srhixmzo6Rg?pwd=1234)  \
ğŸ“ Extraction Code: 1234\
ğŸ“¦ File Size: 6.46 GB \
ğŸ“„ Format: ZIP archive

ğŸ— Dataset Structure
After downloading and extracting, organize the dataset as follows:

```code
DroneVehicle/
â”œâ”€â”€ visible/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ 00001.jpg
â”‚   â”‚   â”œâ”€â”€ 00002.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ val/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ test/
â”‚       â””â”€â”€ ...
â”œâ”€â”€ infrared/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ val/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ test/
â”‚       â””â”€â”€ ...
â””â”€â”€ labels/
    â”œâ”€â”€ train/
    â”‚   â””â”€â”€ ...
    â”œâ”€â”€ val/
    â”‚   â””â”€â”€ ...
    â””â”€â”€ test/
       â””â”€â”€ ...

```

## ğŸš€ Train

To train COMO on your dataset, run:

```bash
torchrun --nproc_per_node=2 --master_port=29502 train.py 
```

> âš ï¸ Adjust dataset path and hyperparameters according to your environment.

---

## ğŸ§ª Validation

To evaluate a trained model, and the checkpoint is in './checkpoint/best.pt':

```bash
python val.py 
```

This will output precision, recall, and mAP results.

---

## ğŸ§ª Compute param. and Flops

```bash
python param.py 
```

This will output param. and Flops.

---

## ğŸ§ª Prediction

```bash
python  predict_write_csv.py
```

This will output predictions.

---

## ğŸ™ Acknowledgements

This repository is built upon [Ultralytics YOLO](https://github.com/ultralytics/ultralytics) and [mamba-ssm](https://github.com/state-spaces/mamba).
We thank the authors for their excellent work.

---

## ğŸ“‘ Citation

If you find this repository useful, please cite our paper:

```bibtex
@article{liu2026cross,
  title={COMO: Cross-mamba interaction and offset-guided fusion for multimodal object detection},
  author={Liu, Chang and Ma, Xin and Yang, Xiaochen and Zhang, Yuxiang and Dong, Yanni},
  journal={Information Fusion},
  volume={125},
  pages={103414},
  year={2026},
  publisher={Elsevier}
}
```

---

## ğŸ“§ Contact

For questions or discussions, please contact **[liu_chang_@whu.edu.cn](liu_chang_@whu.edu.cn)**.

